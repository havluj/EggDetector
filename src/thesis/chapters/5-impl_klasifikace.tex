\chapter{Implementace rozpoznávání obrazu}\label{chap:impl_rozpoz}
V~této kapitole se zamìøíme na implementaci neuronové sítì, která bude mít za cíl rozpoznat, do které kategorie snímek patøí. Jedná se tedy o~klasifikaci do pøedem danıch kategorií. Vstupem pro naše skripty bude obrázek libovolné velikosti. Internì bude bude snímek reprezentován polem hodnot o~velikosti 300~x~300~x~3 (snímek zmenšen na velikost 300~x~300 bodù a zùstane barevnı -- kadı bod obsahuje 3 barevné sloky). Kategorií, do kterıch budeme chtít snímky rozøadit, bude \textbf{jedenáct}:
\begin{description}[labelindent=1cm]
	\item[Kategorie \uv{0}:] Pro snímky, kde je poèet vajec roven \textbf{0}.
	\item[Kategorie \uv{1}:] Pro snímky, kde je poèet vajec roven \textbf{1}.
	\item[Kategorie \uv{2}:] Pro snímky, kde je poèet vajec roven \textbf{2}.
	\item[Kategorie \uv{3}:] Pro snímky, kde je poèet vajec roven \textbf{3}.
	\item[Kategorie \uv{4}:] Pro snímky, kde je poèet vajec roven \textbf{4}.
	\item[Kategorie \uv{5}:] Pro snímky, kde je poèet vajec roven \textbf{5}.
	\item[Kategorie \uv{6}:] Pro snímky, kde je poèet vajec roven \textbf{6}.
	\item[Kategorie \uv{7}:] Pro snímky, kde je poèet vajec roven \textbf{7}.
	\item[Kategorie \uv{8}:] Pro snímky, kde je poèet vajec roven \textbf{8}.
	\item[Kategorie \uv{9}:] Pro snímky, kde je poèet vajec roven \textbf{9}.
	\item[Kategorie \uv{10}:] Pro snímky, kde je poèet vajec roven \textbf{10}.
\end{description}
	
Celé øešení -- pøíprava dat, trénování neuronové sítì, testování funkènosti a mìøení pøesnosti budeme implementovat v~programovacím jazyce Python~3.

\section{Pøíprava dat}
Nástrojem \texttt{Tagger} (viz kapitola \ref{chap:tagger}) jsem oznaèil \textbf{6178 snímkù}. Všechny tyto snímky budou slouit jako trénovací nebo testovací data pro tuto kapitolu.

Abychom nemuseli vyvıjet vlastní skripty pro trénování neuronové sítì, ale mohli pouít skripty standartnì dostupné~\cite{recog_retrain.py}, musíme upravit strukturu trénovacích a testovacích dat.

Souèasná struktura dat je následující:
\begin{figure}[H]
	\dirtree{%
		.1 hnízdo1.
		.2 záznam1.
		.3 imgdata.xml\DTcomment{informace o~poètu vajec v~jednotlivıch snímcích}.
		.3 snímek1.png.
		.3 snímek2.png.
		.3 ....
		.2 záznam2.
		.3 imgdata.xml\DTcomment{informace o~poètu vajec v~jednotlivıch snímcích.}.
		.3 snímek3.png.
		.3 ....
		.2 ....
		.1 hnízdo2.
		.2 záznam3.
		.3 ....
		.2 ....
		.1 ....
	}
\end{figure}

Nová struktura dat, které potøebujeme docílit:
\begin{figure}[H]
	\dirtree{%
		.1 0\DTcomment{Kategorie \textbf{0}}.
		.2 snímek1.png.
		.2 snímek3.png.
		.2 ....
		.1 1\DTcomment{Kategorie \textbf{1}}.
		.2 snímek2.png.
		.2 ....
		.1 2.
		.2 ....
		.1 3.
		.2 ....
		.1 ....
		.1 9.
		.2 ....
		.1 10.
		.2 ....
	}
\end{figure}
Kadá kategorie má vlastní sloku. Do kadé kategorie patøí snímky s~poètem vajec, kterı odpovídá dané kategorii. Jakmile máme trénovací data uspoøádaná do poadované struktury, je vše pøiprano pro trénování neuronové sítì.

\section{Trénování neuronové sítì}
Moderní modely pro rozpoznávání obrazu mají miliony parametrù a je \textbf{extrémnì} vıpoèetnì nároèné je vytrénovat. Uèení \uv{pøenosem modelu}\footnote{Transfer learning.} je technika, která ušetøí spoustu práce vyuitím ji pøedtrénovaného modelu a pøetrénováním pouze finálních vrstev~\cite{decaf}. Více informací k~efektivitì tohoto øešení viz~\cite{decaf}.

Pøedpokladem pro trénování neuronové sítì je nainstalovaná knihovna TensorFlow a všechny její závislosti~\cite{tensor_install}. Model, ze kterého budeme vycházet je \textbf{Inception-v4}\footnote{Dostupnı ke staení na: \url{http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz}}~\cite{inceptionv4}, kterı byl vytrénován spoleèností Google na pøiblinì 1,2 mil. snímkù~\cite{v4trainingsize}. V~soutìi ImageNet~\cite{imagenet} drí model Inception-v4 nejlepšího skóre: Top-1 Accuracy\footnote{Odpovìï modelu (ta s~nejvyšší pravdìpodobností) pøesnì odpovídala oèekávanému vısledku.} 80.2\% a Top-5 Accuracy\footnote{Kterákoliv z~5 nejpravdìpodobnìjších odpovìdí modelu odpovídala oèekávanému vısledku.} 95.2\%~\cite{imagenetresults}.

Googlem poskytovanı skript pro pøetrénování finálních vrstev nepodporuje nejnovìjší model Inception-v4. Staèí však pár modifikací a mùeme novı model pouít. Upravenı skript se nachází v~pøíloze \ref{chap:cd}.

\subsection{Struktura aplikace}
Na disku vytvoøíme sloku \texttt{egg\_recognition}, ve které se budeme pohybovat. Budeme potøebovat tuto strukturu:
\begin{figure}[H]
	\dirtree{%
		.1 egg\_recognition\DTcomment{pracovní sloka}.
		.2 bottlenecks.
		.2 models.
		.3 inception\_v4.pb\DTcomment{pøedtrénovanı model}.
		.2 training\_summaries.
		.2 result\DTcomment{umístìní vısledného modelu}.
		.2 training\_data\DTcomment{trénovací data ve formátu specifikovaném vıše}.
	}
\end{figure}

\noindent Poté spustíme pøipravenı skript \texttt{retrain.py}:
\begin{lstlisting}[language=bash]
cd egg_recognition
python3 retrain.py \
	--bottleneck_dir=bottlenecks \
	--how_many_training_steps=8000 \
	--model_dir=models/ \
	--summaries_dir=training_summaries/ \
	--output_graph=result/egg_classifier_graph.pb \
	--output_labels=result/egg_classifier_labels.txt \
	--image_dir=training_data \
	--print_misclassified_test_images
	--random_crop=16
	--random_scale=7
	--random_brightness=4
\end{lstlisting}
Hodnoty parametrù \texttt{how\_many\_training\_steps}, \texttt{random\_brightness}, \newline\texttt{random\_scale} a \texttt{random\_crop} mùeme zmìnit. K~hodnotám uvedenım vıše jsem dospìl opakovanım testováním, kde tyto hodnoty produkovaly nejlepší vısledky. Skript \texttt{retrain.py}~\cite{recog_retrain.py} poskytuje nejlepší dokumentaci všech dostupnıch parametrù.

\section{Ovìøení funkènosti a vısledky}
Vytrénovanı a vyexportovanı model mùeme otestovat pomocí veøejnì dostupného skriptu \texttt{label\_image.py}~\cite{recog_label_image.py}:
\begin{lstlisting}[language=bash]
cd egg_recognition
python3 ~/tensorflow/examples/image_retraining/label_image.py \
	--graph=result/egg_classifier_graph.pb \
	--labels=/tmp/output_labels.txt \
	--output_layer=final_result:0 \
	--image=test_image.jpg
\end{lstlisting}

\noindent Vısledek je prezentován v~následujícím formátu (hodnoty mohou bıt odlišné):
\begin{lstlisting}[language=bash]
5 (score = 0.62071)
4 (score = 0.44595)
6 (score = 0.43252)
0 (score = 0.43049)
9 (score = 0.00032)
\end{lstlisting}

\section{Závìr}
Dokázali jsme, e øešení funguje. Pøi hromadném testu dat zjistíme, e tato implementace \textbf{není} pøíliš efektivní i pøesto, e náš trénovací vzorek dat je pomìrnì velkı (\textbf{6178 snímkù}). U ze samotného vısledku pøi vyhodnocení pouze jednoho snímku je vidìt, e si sí není jistá, do jaké kategorie danı snímek zaøadit. Všechny vısledky mají buï relativnì nízké skóre nebo naopak všechny pomìrnì vysoké. Bohuel se nedostáváme k~vısledku, ve kterém by byla pouze jedna kategorie dominantní\footnote{Sí by jedné kategorii pøiøadila vysoké skóre (> 80\%) a zbytek kategorií by mìl skóre nízké.}.

Nejvìtší problém spoèívá v~\textbf{malıch rozdílech mezi jednotlivımi kategoriemi}. Vajíèka tvoøí pouze malou èást snímku, take rozdíl mezi jedním nebo dvìmi vajíèky je malı. \textbf{Vìtšina plochy snímku se stává šumem}, kterı \uv{mate} tuto implementaci. Kdyby kategorie reprezentovaly dvì velmi odlišné vìci, jako napøíklad auto a psa, bylo by vıraznì snazší snímek mezi tyto dvì dramaticky odlišné kategorie rozøadit.

Øešení by se stalo mnohem efektivnìjším v~pøípadì, kdyby snímky, které sí vyhodnocuje, byly pøedem zpracované a upravené. Normalizace jasu a pøedevším oøezání snímku tak, aby na nìm zbyla pouze vajíèka, by dramaticky zvıšila efektivitu této implementace.

Tato kapitola neposkytla vısledky, ve které jsem doufal. Je zde ale prostor pro vylepšení, která by toto øešení mohla udìlat efektivnìjší ne detekce objektù popsaná v~kapitole \ref{chap:impl_detekce}.