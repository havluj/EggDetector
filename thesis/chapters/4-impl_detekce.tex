\chapter{Implementace detekování objektù}\label{chap:impl_detekce}
V této kapitole se zamìøíme na implementaci neuronové sítì, která bude slouit k detekci objektù. V rámci této práce nás bude zajímat pouze jeden objekt: vejce. 

Abychom mohli vytrénovat novı model, kterı je schopnı detekce vajec, je potøeba, abychom snímky a data pøevedli do speciálního formátu. Pro pouítí a validaci modelu budeme pouívat skript, u kterého bude vstupem obrázek libovolné velikosti. Internì bude zmenšen na velikost 300~x~300 bodù. Snímek bude reprezentován pole hodnot o velikosti 300~x~300~x~3 (snímek velikosti 300~x~300 bodù a zùstane barevnı -- kadı bod obsahuje 3 barevné sloky. Jakmile provedeme detekci objektù, musíme objekty klasifikovat do pøedem stanovenıch kategorií. Kategorie, do které budeme chtít snímky rozøadit, bude pouze \textbf{1}:
\begin{description}[labelindent=1cm]
	\item[Kategorie \uv{egg}:] Objekt vejce.
\end{description}

Celé øešení -- pøíprava dat, trénování neuronové sítì, testování funkènosti a mìøení pøesnosti budeme implementovat v programovacím jazyce Python~3.

\section{Pøíprava vıvojového prostøedí}
Abychom mohli pouívat \texttt{TensorFlow Object Detection API}, je potøeba následnì pøipravit vıvojové prostøedí:
\begin{enumerate}
	\item Nainstalovat \texttt{Python~3} a \texttt{pip3}.
	\item Stáhnout repositoø s TensorFlow modely: \texttt{git clone https://github.com/tensorflow/models}.
	\item Nainstalovat modely: \texttt{cd models/research \&\& python3 setup.py}.
	\item Pøidat tyto øádky do \texttt{\textasciitilde/.bashrc} (path\_to\_models\_directory nahradíme skuteènım umístìním modelù):
	\begin{lstlisting}[language=bash]
	export MODELS=path_to_models_directory
	export PYTHONPATH=$MODELS:$MODELS/slim
	export OBJ_DET=$MODELS/object_detection
	\end{lstlisting}
	\item Nainstalovat TensorFlow: \texttt{sudo pip3 install tensorflow-gpu} nebo \texttt{sudo pip3 install tensorflow}. Více informací viz \cite{tensor_install}.
	\item Pro ovìøení instalace spustíme interaktivní \texttt{Python 3}:
	\begin{lstlisting}[language=Python]
	import tensorflow as tf
	hello = tf.constant('EggDetector!')
	sess = tf.Session()
	print(sess.run(hello))
	\end{lstlisting}
	Systém by mìl odpovìdìt \uv{\texttt{EggDetector!}}.
\end{enumerate}

\section{Pøíprava dat}
Nástrojem LabelImg (viz kapitola \ref{subsec:labelimg}) jsem oznaèil \textbf{1800} vajec. Data je potøeba rozdìlit na trénovací a testovací. Testovací data slouí k validaci a vyhodnocení úspìšnosti trénovaného modelu. Standardnì se data dìlí pøiblinì v pomìru 9:1 ve prospìch trénovacích dat. Data jsem rozdìlil následnovnì:
\begin{itemize}
	\item \textbf{1701} vıskytù vajec jako trénovací data,
	\item \textbf{189} vıskytù vajec jako data validaèní.
\end{itemize}

Trénovací data pøesuneme do pracovní sloky. Po pøesunutí je nutné opravit XML záznamky vygenerované nástrojem \texttt{LabelImg}. Ve slokách, kde máme trénovací data a testovací data pustíme následující pøíkaz:
\begin{lstlisting}[language=bash]
for fullfile in *.jpg; do
	filename=$(basename "$fullfile")
	filename="${filename%.*}"
	echo "$filename".xml
	awk -v var="$filename" 'NR==3{$0="\t<filename>"var".jpg</filename>"}1;' "$filename".xml > temp.xml && mv temp.xml "$filename".xml
done

for fullfile in *.png; do
	filename=$(basename "$fullfile")
	filename="${filename%.*}"
	echo "$filename".xml
	awk -v var="$filename" 'NR==3{$0="\t<filename>"var".png</filename>"}1;' "$filename".xml > temp.xml && mv temp.xml "$filename".xml
done
\end{lstlisting}

\section{Struktura projektu}
Projekt, ve kterém budeme celou implementaci tvoøit, bude mít následující strukturu:
\begin{figure}[H]
	\dirtree{%
		.1 object-detection-training\DTcomment{pracovní sloka}.
		.2 training\DTcomment{sloka s konfigurací}.
		.3 checkpoint\_model\DTcomment{data modelu, ze kterého budeme vycházet}.
		.3 egg\_label\_map.pbtxt.
		.3 pipeline.config.
		.2 test\_images\DTcomment{testovací obrázky k validaci}.
		.2 frozen\_graph\DTcomment{vıslednı, exportovanı graf}.
		.2 images\DTcomment{všechna testovací a trénovací data}.
		.3 test\DTcomment{testovací data}.
		.3 train\DTcomment{trénovací data}.
		.2 export\_inference\_graph.py.
		.2 generate\_tfrecord.py.
		.2 xml\_to\_csv.py.
	}
\end{figure}

Stejná struktura je dostupná u pøiloeného zdrojového kódu v pøíloze \ref{chap:cd}, konkrétnì ve sloce \texttt{src/object-detection-training}.

Všechny skripty, které pouíváme k trénování a validaci jsou dostupné v pøíloze \ref{chap:cd}.

\section{Trénování neuronové sítì}
Moderní modely pro rozpoznávání obrazu mají miliony parametrù a je \textbf{extrémnì} vıpoèetnì nároèné je vytrénovat. Uèení \uv{pøenosem modelu}\footnote{Transfer learning.} je technika, která ušetøí spoustu práce vyuitím ji pøed-trénovaného modelu a pøetrénováním pouze finálních vrstev~\cite{decaf}. Trénování sítì \uv{od nuly} je standardnì efektivnìjší, ale v mém testování jsem ve vısledcích rozdíl nepocítil. Proto jsem se rozhodl o pouítí ji pøedtrénovaného modelu.

\subsection{Vıchozí model}
V rámci této implementace jsem zkusil pouil tøi rùzné modely, které slouily jako startovní bod pro trénování. Nejlepší vısledky se dostavily pøi pouítí modelu \texttt{ssd\textunderscore mobilenet\textunderscore v1\textunderscore coco}\footnote{Ke staení na \url{http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz} nebo v pøíloze \ref{chap:cd}.}~\cite{tensor_models}. Modely, které nebyly tak úspìšné jsou: \texttt{faster\_rcnn\_nas\_coco}\footnote{Ke staení na \url{http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2017_11_08.tar.gz}.} a \texttt{faster\_rcnn\_resnet101\_coco}\footnote{Ke staení na \url{http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_coco_2017_11_08.tar.gz}.}. Staenı model umístíme do sloky \texttt{training} v pracovním adresáøi. Další modely, jejich rychlost a efektivita jsou zobrazeny na obrázku \ref{fig:tensor_models}.

\begin{figure}
	\centering
	\includegraphics[width=0.6\textwidth]{media/tensor_models.png}
	\caption{Pøed-trénované modely poskytované spoleèností Google.}
	\label{fig:tensor_models}
\end{figure}

\subsection{Konfigurace}
Nyní je èas nakonfigurovat parametry, podle kterıch se bude neuronová sí øidit pøi uèení. TensorFlow Object Detection API pouívá soubory \texttt{protobuf} ke konfiguraci trénovacího a evaluaèního procesu. Konfiguraèní soubor je rozdìlen do 5 èástí: \texttt{model}, \texttt{train\_config}, \texttt{eval\_config}, \texttt{train\_input\_config} a \texttt{eval\_input\_config}~\cite{tensor_od_config}.

Pro kadı typ aplikace jsou vhodné jiné parametry. Vıslednı konfiguraèní soubor pouitı spoleènì s modelem \texttt{ssd\_mobilenet\_v1\_coco} je vypsán v pøíloze \ref{chap:config_detection}.

\subsection{Trénovací data}
TensorFlow Object Detection API oèekává trénovací data ve formátu \texttt{TFRecord}~\cite{tfrecord}. Do pøílohy \ref{chap:cd} jsem pøiloil všechny skripty pro vygenerování tìchto souborù z trénovacích dat. Staèí nejdøíve vytvoøit z XML záznamù vytvoøenıch nástrojem 
%
%generate csv files from xml
%`python3.5 xml_to_csv.py`
%
%generate train data
%`python3.5 generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=data/train.record`
%
%generate test data
%`python3.5 generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=data/test.record`
%


\subsection{Trénování}
checkpointy, ukázky tensorboard, atd
sledovani trenovani
muzeme trenovat lokalne nebo na cloudu

\subsubsection{Trénování lokálnì}
%train the network
%`$OBJ_DET/train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config`
%
\subsubsection{Trénování na Google Cloud Platform}

\section{Ovìøení funkènosti a vısledky}
%export inference graph
%```
%python3.5 export_inference_graph.py \
%--input_type image_tensor \
%--pipeline_config_path training/ssd_mobilenet_v1_coco.config \
%--trained_checkpoint_prefix training/model.ckpt-7918 \
%--output_directory frozen_graph
%```

ipnb notebook

ukazka vysledku trenovani podle jednoho modelu a trenovani podle druheho modelu

\section{Závìr}

