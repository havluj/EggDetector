\chapter{Nástroje}\label{chap:nastroje}
Pøípravu a zpracování dat si mùžeme usnadnit pomocí nìkolika nástrojù. Zamìøíme se na hromadné stažení dat ze serveru \url{http://athena.pef.czu.cz/ptacionline/} a jejich \uv{proèištìní}. Dále si pøedstavíme nástroje, ve kterých obohatíme stažené snímky o informace potøebné k trénování neuronové sítì.

\section{Hromadné stažení dat}\label{sec:hromadne_stazeni_dat}
\subsection{Získání dat}\label{subsec:hromadne_stazeni_dat}
Abychom nemuseli stahovat snímky jeden po druhém manuálnì, pomùžeme si napsáním jednoduchého skriptu, který stáhne všechny snímky za nás. K tomu nám postaèí dva nástroje: \texttt{bash} a \texttt{wget}. Tento skript stáhne veškerá data, která jsou na serveru \url{http://athena.pef.czu.cz/ptacionline/} dostupná. Detailní dokumentace skriptu je k nalezení v pøíloze \ref{chap:cd}).
\noindent\begin{lstlisting}[caption={Hromadné stažení dat ze serveru athena.pef.czu.cz.},label={alg:download},language=bash]
#!/bin/bash

DIRECTORY=data
URL=http://athena.pef.czu.cz/ptacionline/

wget -o log.txt -nv --show-progress -c -P "$DIRECTORY" -r -np -nH --cut-dirs=1 -R index.html "$URL"
\end{lstlisting}

\vspace{0.5cm}\noindent
Struèné vysvìtlení pøíkazu \texttt{wget}, který používáme na poslední øádce skriptu \ref{alg:download}:
\begin{itemize}
	\item Všechny složky a podsložky dostupné na serveru budou staženy lokálnì do složky \texttt{\$DIRECTORY}.
	\item \texttt{-o log.txt} vytvoøí záznam do souboru \texttt{log.txt}.
	\item \texttt{-nv} zobrazuje pouze chyby, ne varování.
	\item \texttt{--show-progress} ukáže progres stahování.
	\item \texttt{-c} -- pokraèuj ve stahování nedokonèených souborù.
	\item \texttt{-r} -- rekurzivnì stahuj podsložky.
	\item \texttt{-np} -- nestahuj soubory v složkách výše, než \texttt{ptacionline}.
	\item \texttt{-nH} -- nestahuj do složky, která se jmenuje stejnì jako doména, ale pøímo do \texttt{\$DIRECTORY}.
	\item \texttt{--cut-dirs=1} -- ve složce \texttt{\$DIRECTORY} vynech první složku (\texttt{ptacionline}).
	\item \texttt{-R index.html} -- nestahuj soubory \texttt{.html}.
\end{itemize}

\subsection{Èištìní dat}
Skript, který jsme pøedstavili v kapitole \ref{subsec:hromadne_stazeni_dat}, stáhne veškerá data z daného serveru. Mezi takovými daty jsou snímky, které jsou pro nás užiteèné, ale zbytek stažených dat je pro nás zbyteèný. Abychom se v datech mohli lépe orientovat a ušetøit místo na pevném disku, bylo by vhodné nepotøebná data smazat. Pro tento úèel naprogramujeme jednoduchý nástroj v programovacím jazyce \texttt{Java}, který automaticky ponechá data potøebná a data nepotøebná smaže.

Zdrojový kód a dokumentace nástroje \textbf{FolderTrimmer} je k nalezení v pøíloze \ref{chap:folder_trimmer}. Výsledný program staèí spustit a složku, která má být promazána, mu pøedat jako argument: \texttt{run.sh /home/demo/eggs/data}.

FolderTrimmer funguje ve dvou režimech. První, základní režim, smaže všechny soubory jiného typu než PNG, TXT a XML. V pøípadì, že složka neobsahuje další složku nebo alespoò jeden soubor typu PNG, TXT nebo XML, bude také smazána. Druhý režim funguje stejnì jako první, ale smaže všechny složky, které neobsahují soubor \textbf{imgdata.xml}. To umožní vymazání všech dat, které nejsou relevantní pro trénování neuronové sítì. První øežim spustíme pøíkazem \texttt{run.sh false "cesta\textunderscore ke\textunderscore slozce"}. Druhý režim spustíme pøíkazem \texttt{run.sh true "cesta\textunderscore ke\textunderscore slozce"}.

\section{Pøíprava trénovacích a testovacích dat}\label{sec:priprava_dat}
Když máme všechna potøebná data stažená, je potøeba je pøipravit tak, abychom je mohli použít k trénování neuronové sítì. Pøíprava dat se liší podle typu implementace, který zvolíme.
\subsection{Tagger}
ukazka
\subsection{LabelImg}
ukazka

\section{Zpracování trénovacích a testovacích dat}\label{sec:trenovani}
todo ve vysledku pujde do impelemtaci